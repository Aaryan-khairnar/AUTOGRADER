{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aaryan-khairnar/AUTOGRADER/blob/main/AutoGrader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SE2rjs8s4Jvx"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import google.generativeai as genai\n",
        "\n",
        "api_key = getpass.getpass(\"Enter your Gemini API Key: \")\n",
        "genai.configure(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLABluAPqQuU"
      },
      "outputs": [],
      "source": [
        "MODEL_CONFIG = {\n",
        "  \"temperature\": 0.2,\n",
        "  \"top_p\": 1,\n",
        "  \"top_k\": 32,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKcen0ujqQrk"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(model_name = \"gemini-1.5-flash\",\n",
        "                              generation_config = MODEL_CONFIG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMS7zsaScSdk"
      },
      "outputs": [],
      "source": [
        "# UPLOADING QUESTION PAPER\n",
        "\n",
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "\n",
        "# Upload the image file\n",
        "uploaded = files.upload()\n",
        "\n",
        "file_path = list(uploaded.keys())[0]  # Gets the first uploaded file name\n",
        "\n",
        "import base64\n",
        "\n",
        "def encode_pdf_to_base64(file_path):\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        return base64.b64encode(file.read()).decode(\"utf-8\")\n",
        "\n",
        "base64_pdf = encode_pdf_to_base64(file_path)\n",
        "file_data = Path(file_path).read_bytes()\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "               You are a specialist in extracting and comprehending Handwritten/printed text from various file formats.\n",
        "               Input files such as images, PDFs, and text documents will be provided,\n",
        "               and your task is to return the extracted text in markdown format.\n",
        "               You are NOT allowed to summarise the data, you must retrun all of it word to word.\n",
        "               \"\"\"\n",
        "\n",
        "response = model.generate_content(\n",
        "    contents=[\n",
        "        {\"role\": \"user\", \"parts\": [  # Must be a list of dictionaries\n",
        "            {\"text\": system_prompt},\n",
        "            {\"inline_data\": {\"mime_type\": \"application/pdf\", \"data\": base64_pdf}}\n",
        "        ]}\n",
        "    ]\n",
        ")\n",
        "\n",
        "QuestionPaper = response.text\n",
        "print(QuestionPaper)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBxmh1GXYVN3"
      },
      "outputs": [],
      "source": [
        "# UPLOADING ANSWER SHEET\n",
        "\n",
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "\n",
        "# Upload the image file\n",
        "uploaded = files.upload()\n",
        "\n",
        "file_path = list(uploaded.keys())[0]  # Gets the first uploaded file name\n",
        "\n",
        "#for file_name in uploaded.keys():\n",
        "#    print(f\"Processing file: {file_name}\")\n",
        "#    file_path = Path(file_name)\n",
        "\n",
        "import base64\n",
        "\n",
        "def encode_pdf_to_base64(file_path):\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        return base64.b64encode(file.read()).decode(\"utf-8\")\n",
        "\n",
        "base64_pdf = encode_pdf_to_base64(file_path)\n",
        "file_data = Path(file_path).read_bytes()\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "               You are a specialist in extracting and comprehending Handwritten/printed text from various file formats.\n",
        "               Input files such as images, PDFs, and text documents will be provided,\n",
        "               and your task is to return the extracted text in markdown format.\n",
        "               You are NOT allowed to summarise the data, you must retrun all of it word to word.\n",
        "               \"\"\"\n",
        "\n",
        "response = model.generate_content(\n",
        "    contents=[\n",
        "        {\"role\": \"user\", \"parts\": [  # Must be a list of dictionaries\n",
        "            {\"text\": system_prompt},\n",
        "            {\"inline_data\": {\"mime_type\": \"application/pdf\", \"data\": base64_pdf}}\n",
        "        ]}\n",
        "    ]\n",
        ")\n",
        "\n",
        "AnswerPaper = response.text\n",
        "print(AnswerPaper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16MtTMOxEQPg"
      },
      "outputs": [],
      "source": [
        "# Grading prompt\n",
        "strictness_level = 1.5 #out of 5\n",
        "\n",
        "prompt_text = f\"\"\"\n",
        "You are an AI educator with expertise in automated grading and feedback generation for student answers. You will be provided with two markdown files:\n",
        "1. A **Question Paper** that includes:\n",
        "   - All questions\n",
        "   - The grading scheme for each question (mark distribution)\n",
        "   - Any instructions or special rules (e.g., \"Attempt any 4 out of 5 questions\", \"Internal choice\", etc.)\n",
        "2. A **Student Answer Sheet** that contains the student's answers in markdown format.\n",
        "3. A **Strictness Level (1-5):**\n",
        "   - **1 (Least Strict):** Accepts vague or incomplete answers and still gives decent marks.\n",
        "   - **3 (Moderate Strictness):** Requires reasonable accuracy and inclusion of key concepts.\n",
        "   - **5 (Most Strict):** Only highly accurate, well-structured answers receive full marks.\n",
        "\n",
        "### Your tasks:\n",
        "\n",
        "1. **Extract the Grading Scheme:**\n",
        "   - Read the question paper and extract the grading scheme for each question.\n",
        "   - Identify any instructions (such as internal choices) that affect how questions should be graded.\n",
        "\n",
        "2. **Identify Relevant Keywords and Concepts:**\n",
        "   - Without explicit keywords provided, analyze the question paper to determine which key terms or concepts are expected in the answer.\n",
        "   - Use this understanding to search for those concepts in the student's answers.\n",
        "\n",
        "3. **Map Questions to Answers:**\n",
        "   - The order of answers in the answer sheet may be random. Carefully match each answer to its corresponding question from the question paper.\n",
        "   - Ensure that each questionâ€™s answer is evaluated against the correct criteria.\n",
        "   - The markdown text of answer sheet can have some incorrect text as it comes from an ocr, keep that in mind.\n",
        "   - If the mcq answer is not correct but you see the option written (A/B/C/D) is correct then give correct marks.\n",
        "\n",
        "4. **Grading Process (Based on Strictness Level):**\n",
        "   - For each mapped question and answer pair, evaluate the answer based on the grading scheme and strictness level.\n",
        "   - If the strictness level is **low (1-2):** minor errors, missing explanations, or vague reasoning may still get partial marks.\n",
        "   - If the strictness level is **moderate (3):** requires answers to be mostly correct with reasonable completeness.\n",
        "   - If the strictness level is **high (4-5):** strict evaluation, deducting marks for even minor mistakes or lack of clarity.\n",
        "   - Provide a detailed explanation of how the marks were awarded.\n",
        "\n",
        "5. **Feedback and Improvement Suggestions:**\n",
        "   - Generate constructive feedback for each answer, highlighting strengths and areas for improvement.\n",
        "   - Suggest topics or concepts that the student should review to improve their understanding.\n",
        "\n",
        "6. **Final Summary:**\n",
        "   - Sum up the marks from all questions to calculate the total grade.\n",
        "   - Provide a comprehensive summary of the student's overall performance and list the topics they can focus on to improve.\n",
        "\n",
        "### **Input Format:**\n",
        "- **Question Paper:** Markdown file containing all questions, grading schemes, and instructions: {QuestionPaper}\n",
        "- **Student Answer Sheet:** Markdown file containing the student's answers: {AnswerPaper}\n",
        "- **Strictness Level:** A decimal value between 1 and 5 that determines how strictly the answers are graded: {strictness_level}\n",
        "\n",
        "### **Output Format:**\n",
        "Your response should include:\n",
        "- A mapping of questions to answers.\n",
        "- For each question:\n",
        "  - The grade awarded (out of the specified marks).\n",
        "  - An explanation of the grading.\n",
        "  - Constructive feedback.\n",
        "- A final summary with the total marks and overall improvement suggestions.\n",
        "\n",
        "Please process the provided markdown inputs and generate a cleaned, coherent evaluation based on the specified strictness level.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcN3I4ZG44X8"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=api_key)\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\", contents=prompt_text\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NA76NUwypa4z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}